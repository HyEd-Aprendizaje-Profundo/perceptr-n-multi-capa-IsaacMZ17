{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbfc33a8",
   "metadata": {},
   "source": [
    "# Práctica 1: Perceptrón multicapa.\n",
    "\n",
    "Tu jefe pidió a RH que recolectara datos de desempeño de tus compañeros, los resultados se almacenaron en un csv. El punto critico de estos datos es la satisfacción del empleado, entonces ¿Podremos estimar la satisfacción de los empleados con los datos recabados?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ffe3db6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "df = pd.read_csv('Extended_Employee_Performance_and_Productivity_Data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67edad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include=['number']).drop('Employee_ID',axis=1)\n",
    "\n",
    "cols = list(numeric_columns)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(cols), figsize=(5 * len(cols), 4))\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    axes[i].hist(df[col], bins=20, color='skyblue', edgecolor='black')\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Frecuencia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4265314b",
   "metadata": {},
   "source": [
    "**Problemas**, tenemos distribuciones con picos, esos nos indica categorías. Por otro lado, tenemos variables con \"valles\" en su distribución (distribuciones multimodales) por lo que resultaría óptimo aplicar técnicas de feature engeneering. Por último tenemos distribuciones uniformes, por lo que cada una requeriría un procesamiento indivudual, hagamos la vista gorda e intentemos ajustar un MLP con estos datos, solo estandaricemos nuestros datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40920f8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Implementación de Red:\n",
    "\n",
    "To**memos los datos numéricos como nuestra variable X, y la variable objetivo como ***'Employee_Satisfaction_Score'***.\n",
    "- **Actividad 1**: Para todos los strings ``'@modif@'`` que aparescan en el siguiente bloque de código cámbialos para que el código funcione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd081ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Employee_Satisfaction_Score', axis=1)\n",
    "y = df['Employee_Satisfaction_Score']\n",
    "y = y.apply(lambda x: round(x)-1) \n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_cols)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_standar = scaler.fit_transform(X_encoded)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_standar, y, test_size=0.33, random_state=42)\n",
    "\n",
    "y_onehot_train = tf.keras.utils.to_categorical(y_train, 5)\n",
    "y_onehot_test = tf.keras.utils.to_categorical(y_test, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5920d085",
   "metadata": {},
   "source": [
    "- **Actividad 2:** Implementa 3 arquitecturas de MLP, cada una con su propio nombre, cambiando la estructura de dichas arquitecturas (capas, neuronas por capa, función de activación, etc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dbf970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model_simple = Sequential(name='MLP_Simple')\n",
    "model_simple.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_simple.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model_medium = Sequential(name='MLP_Medium')\n",
    "model_medium.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_medium.add(Dense(32, activation='tanh'))\n",
    "model_medium.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model_deep = Sequential(name='MLP_Deep')\n",
    "model_deep.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_deep.add(Dense(64, activation='relu'))\n",
    "model_deep.add(Dense(32, activation='tanh'))\n",
    "model_deep.add(Dense(5, activation='softmax'))\n",
    "\n",
    "print(\"Modelo Simple:\")\n",
    "model_simple.summary()\n",
    "print(\"\\nModelo Medium:\")\n",
    "model_medium.summary()\n",
    "print(\"\\nModelo Deep:\")\n",
    "model_deep.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b8c585",
   "metadata": {},
   "source": [
    "- **Actividad 3:** Compila y ajusta tus tres modelos con sus respectivos hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9813c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "\n",
    "model_simple.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_medium.compile(optimizer=RMSprop(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_deep.compile(optimizer=SGD(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_simple = model_simple.fit(\n",
    "    X_train, y_onehot_train,\n",
    "    epochs=30, batch_size=32,\n",
    "    validation_data=(X_test, y_onehot_test),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history_medium = model_medium.fit(\n",
    "    X_train, y_onehot_train,\n",
    "    epochs=40, batch_size=64,\n",
    "    validation_data=(X_test, y_onehot_test),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history_deep = model_deep.fit(\n",
    "    X_train, y_onehot_train,\n",
    "    epochs=50, batch_size=128,\n",
    "    validation_data=(X_test, y_onehot_test),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08db50b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d92ff84b",
   "metadata": {},
   "source": [
    "- **Actividad 4:** Sube tus cambios al repositorio, envía el link de tu repositorio a la actividad 2 de tu checkpoint 2 y contesta las preguntas de dicha actividad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
